import os
import random
import numpy as np
import matplotlib.pyplot as plt
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.metrics import f1_score
from natsort import natsorted
from src.models.unet import UNet
from scipy.spatial import distance as dist
from imutils import perspective

# -------------------------------
# Veri Hazırlık Fonksiyonları
# -------------------------------
def convert_one_channel(img):
    if len(img.shape) > 2:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img

def pre_images(resize_shape, path):
    dirs = natsorted(os.listdir(path))
    images_list = []
    sizes = []

    for filename in dirs:
        img_path = os.path.join(path, filename)
        img = cv2.imread(img_path)

        if img is None:
            raise FileNotFoundError(f"Görüntü dosyası bulunamadı: {img_path}")

        sizes.append(img.shape[:2])
        img = cv2.resize(img, resize_shape, interpolation=cv2.INTER_AREA)
        img = convert_one_channel(img)
        images_list.append(img)

    images = np.stack(images_list, axis=0)
    images = images.reshape(len(dirs), 1, resize_shape[1], resize_shape[0])
    return images, sizes

def pre_masks(resize_shape, path):
    dirs = natsorted(os.listdir(path))
    masks_list = []

    for filename in dirs:
        mask_path = os.path.join(path, filename)
        mask = cv2.imread(mask_path)

        if mask is None:
            raise FileNotFoundError(f"Maske dosyası bulunamadı: {mask_path}")

        mask = cv2.resize(mask, resize_shape, interpolation=cv2.INTER_NEAREST)
        mask = convert_one_channel(mask)
        masks_list.append(mask)

    masks = np.stack(masks_list, axis=0)
    masks = masks.reshape(len(dirs), 1, resize_shape[1], resize_shape[0])
    return masks

def midpoint(ptA, ptB):
    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)


def CCA_Analysis(orig_image, predict_image, erode_iteration, open_iteration):
    # Predict image'in boyutlarını kontrol et
    print(f"Predict image shape before processing: {predict_image.shape}")

    # Fazladan boyutları kontrol et ve sıkıştır
    while len(predict_image.shape) > 2 and predict_image.shape[0] == 1:
        predict_image = predict_image.squeeze(0)  # İlk ekseni sıkıştır

    # Eğer batch boyutu varsa (örneğin 2, 1, 512, 512), sadece ilk örneği al
    if len(predict_image.shape) == 4:
        predict_image = predict_image[0]  # İlk örneği al
        print(f"Predict image shape after batch removal: {predict_image.shape}")

    # Eğer hala 3 boyutluysa, tek kanallı hale getir
    if len(predict_image.shape) == 3 and predict_image.shape[0] == 1:
        predict_image = predict_image.squeeze(0)  # İlk ekseni sıkıştır
        print(f"Predict image shape after squeeze: {predict_image.shape}")

    # Predict image'i 8-bit formatına dönüştür
    predict_image = predict_image.astype(np.uint8)

    kernel1 = np.ones((5, 5), dtype=np.float32)
    kernel_sharpening = np.array([[-1, -1, -1],
                                  [-1, 9, -1],
                                  [-1, -1, -1]])
    image = predict_image
    image2 = orig_image

    # Görüntü işlemleri
    image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel1, iterations=open_iteration)
    image = cv2.filter2D(image, -1, kernel_sharpening)
    image = cv2.erode(image, kernel1, iterations=erode_iteration)

    thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    labels = cv2.connectedComponents(thresh, connectivity=8)[1]
    a = np.unique(labels)
    count2 = 0
    for label in a:
        if label == 0:
            continue

        mask = np.zeros(thresh.shape, dtype="uint8")
        mask[labels == label] = 255
        cnts, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts = cnts[0]
        c_area = cv2.contourArea(cnts)

        if c_area > 2000:
            count2 += 1

        rect = cv2.minAreaRect(cnts)
        box = cv2.boxPoints(rect)
        box = np.array(box, dtype="int")
        box = perspective.order_points(box)
        color = (0, 255, 0)
        cv2.drawContours(image2, [box.astype("int")], 0, color, 2)

    teeth_count = count2
    return image2, teeth_count


# -------------------------------
# PyTorch Dataset Sınıfı
# -------------------------------
class DentalDataset(Dataset):
    def __init__(self, images, masks):
        self.images = images
        self.masks = masks

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx], dtype=torch.float32)
        mask = torch.tensor(self.masks[idx], dtype=torch.float32)
        return image, mask

# -------------------------------
# Veri Yolları ve Ayarlar
# -------------------------------
base_path = "/media/baran/Disk1/Segmentation-of-Teeth-in-Panoramic/dataset/DentalPanoramicXrays"
images_path = os.path.join(base_path, "images/")
masks_path = os.path.join(base_path, "masks/")

# Görüntü ve Maske Verilerinin Hazırlanması
X, X_sizes = pre_images((512, 512), images_path)
Y = pre_masks((512, 512), masks_path)

# Normalizasyon
X = X / 255.0
Y = Y / 255.0

# Eğitim ve Test Setlerine Ayırma
x_train, y_train = X[:105], Y[:105]
x_test, y_test = X[105:], Y[105:]

# Dataset ve DataLoader
train_dataset = DentalDataset(x_train, y_train)
test_dataset = DentalDataset(x_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)

# Model Tanımı
model = UNet()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Loss ve Optimizer
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Eğitim Döngüsü
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    for images, masks in train_loader:
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader):.4f}")

# Değerlendirme ve Post-Processing
# Değerlendirme ve Post-Processing
model.eval()
with torch.no_grad():
    for idx, (images, masks) in enumerate(test_loader):
        images = images.to(device)
        outputs = model(images).squeeze(0).cpu().numpy()  # Çıkış maskesi
        pred_mask = (outputs > 0.5).astype(np.uint8) * 255  # İkili maske

        # Orijinal görüntüyü işlerken dikkat
        original_image = images.cpu().numpy()[0, 0, :, :] * 255  # İlk görüntüyü al ve skala yap
        original_image = original_image.astype(np.uint8)  # 8-bit dönüşüm
        original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)  # BGR formatına dönüştür

        # Post-processing ve görselleştirme
        result_image, teeth_count = CCA_Analysis(original_image, pred_mask, erode_iteration=3, open_iteration=2)

        # Görselleştirme
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.title("Original Image")
        plt.imshow(original_image, cmap="gray")

        plt.subplot(1, 2, 2)
        plt.title(f"Processed Image - Teeth Count: {teeth_count}")
        plt.imshow(result_image)

        plt.show()

        if idx == 4:  # Sadece ilk 5 görüntü üzerinde değerlendirme
            break
